---
title: "[딥러닝] 확률적 경사 하강법"
categories: 
- 딥러닝
tags:
- 확률적 경사 하강법
toc: true   #Table Of Contents 목차 
use_math: true
toc_sticky: true
---

## SGD와 Mini-Batch GD

- 경사 하강법 방식은 전체 학습 데이터를 기반으로 GD를 계산. 하지만 입력 데이터가 크고 레이어가 많을수록 GD를 계산하는데 많은 Computing 자원이 소모
- 이를 극복하기 위해 Stochastic Gradient Descent와 Mini-Batch Gradient Dexcent 방식이 도입

| GD(Gradient Dexcent)                | SGD                                                 | Mini - Batch GD                                              |
| ----------------------------------- | --------------------------------------------------- | ------------------------------------------------------------ |
| 전체 학습 데이터를 기반으로 GD 계산 | 전체 학습 데이터 중 한 건만 임의로 선택하여 GD 계산 | 전체 학습 데이터 중 특정 크기만큼(Batch 크기) 임의로 선택해서GD 계산 |

일반적으로 Mini-Batch GD가 대부분의 딥러닝 Framework에서 채택된다. 보통 SGD with Mini-Batch라고도 한다.

특히 keras의 경우 무조건 미니배치 GD를 사용하며 배치 사이즈 = 32가 디폴트 값이다.

## 참고 자료

[딥러닝 CNN 완벽가이드](https://www.inflearn.com/course/%EB%94%A5%EB%9F%AC%EB%8B%9D-cnn-%EC%99%84%EB%B2%BD-%EA%B8%B0%EC%B4%88)

