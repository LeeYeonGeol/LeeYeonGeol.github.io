---
title: "[CNN] 가중치 초기화의 이해"
categories: 
- CNN
toc: true   #Table Of Contents 목차 
use_math: true
toc_sticky: true
---

## 가중치 초기화

### 좋은 가중치 초기화 조건

1. 값이 동일 해서는 안된다. (선형적으로 증가 혹은 감소하기만 한다.)
2. 충분히 작아야 한다. (Weight sum하기 때문에 충분히 작아야 한다.)
3. 적당한 분산(또는 표준편차)를 가져야 한다. 

## Xavier Glorot Initialization

입력 노드와 출력 노드의 갯수를 감안하여 동적으로 Weight  초기화 수행.

> glorot_uniform
>
> 한도값 = $\sqrt \frac{6}{fan \ in + fan \ out}$

> glorot_normal
>
> 표준편차 =  $\sqrt \frac{2}{fan \ in + fan \ out}$

## He Initialization

Relu에 보다 최적화된 가중치 초기화

> he_uniform
>
> 한도값 = $\sqrt \frac {6}{fan \ in}$

> he_normal
>
> 표준편차= $\sqrt \frac {2}{fan \ in}$

## 참고 자료

[딥러닝 CNN 완벽가이드](https://www.inflearn.com/course/%EB%94%A5%EB%9F%AC%EB%8B%9D-cnn-%EC%99%84%EB%B2%BD-%EA%B8%B0%EC%B4%88)

